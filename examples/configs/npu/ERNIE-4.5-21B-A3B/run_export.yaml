### model
model_name_or_path: baidu/ERNIE-4.5-21B-A3B-Paddle
fine_tuning: LoRA

### split
max_shard_size: 5
hf_hub_id: null
output_dir: ./output

### performance
tensor_parallel_degree: 4
pipeline_parallel_degree: 2
sharding_parallel_degree: 1
sharding: stage1
sequence_parallel: True
compute_type: bf16
fp16_opt_level: O2

# device
device: npu
use_attn_mask_start_row_indices: true
moe_use_aux_free: false
moe_multimodal_dispatch_use_allgather: ""
fuse_rope: false
fuse_rms_norm: false
use_flash_attention: true
use_sparse_flash_attn: false
use_fused_head_and_loss_fn: true
use_sparse_head_and_loss_fn: true
pipeline_parallel_config: disable_partial_send_recv disable_batch_p2p_comm enable_clear_every_step_cache
